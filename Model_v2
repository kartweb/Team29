import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_absolute_error, mean_squared_error
from entsoe import EntsoePandasClient
import warnings

warnings.filterwarnings("ignore")

# --- IMPORTANT: PASTE YOUR ENTSO-E API KEY HERE ---
ENTSOE_API_KEY = "c4674c63-8780-42ef-bf6d-f2653b826312"

# --- Main Data Preparation Function ---

def create_modeling_dataframe():
    """
    Executes the full data engineering pipeline, assuming all data sources
    are for Belgium and can be aligned on a UTC time index.
    """
    print("--- Starting Data Engineering Pipeline ---")

    # Step 1: Load local CSV data (Imbalance Actuals and Forecasts)
    print("Step 1: Loading local CSV data...")
    try:
        imbalance_actual = pd.read_csv('C:/Users/diede/Downloads/imbalance_actual.csv')
        imbalance_forecast = pd.read_csv('C:/Users/diede/Downloads/imbalance_forecast.csv')
    except FileNotFoundError as e:
        print(f"Error: A source CSV file was not found. Please check paths.\n{e}")
        return None

    def prepare_local_csv(df):
        """Standardizes CSV data to a 15-minute, timezone-aware UTC index."""
        df['datetime_utc'] = pd.to_datetime(df['datetime_utc'])
        df.set_index('datetime_utc', inplace=True)
        # Crucial Step: Make the naive index timezone-aware (localize to UTC)
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC')
        return df.resample('15min').mean(numeric_only=True)

    df_actual = prepare_local_csv(imbalance_actual)
    df_forecast = prepare_local_csv(imbalance_forecast)
    
    # Merge local data to establish the master DataFrame and date range
    master_df = pd.concat([
        df_actual['price_eur_mwh'].rename('actual_price'),
        df_forecast['price_eur_mwh'].rename('forecast_price')
    ], axis=1)

    # Step 2: Pull API Data
    print("Step 2: Pulling data from ENTSO-E and Open-Meteo APIs...")
    start_date = master_df.index.min().strftime('%Y-%m-%d')
    end_date = master_df.index.max().strftime('%Y-%m-%d')

    # Fetch ENTSO-E Day-Ahead Prices
    try:
        client = EntsoePandasClient(api_key=ENTSOE_API_KEY)
        start_ts = pd.Timestamp(start_date, tz='Europe/Brussels')
        end_ts = pd.Timestamp(end_date, tz='Europe/Brussels')
        prices = client.query_day_ahead_prices('BE', start=start_ts, end=end_ts)
        df_dam = pd.DataFrame(prices, columns=['dam_price'])
        df_dam.index = df_dam.index.tz_convert('UTC') # Convert to UTC for alignment
        df_dam = df_dam.resample('15min').ffill()
    except Exception as e:
        print(f"  - WARNING: Failed to fetch ENTSO-E data. Proceeding without it. Error: {e}")
        df_dam = None

    # Fetch Open-Meteo Weather Data
    params = {"latitude": 50.85, "longitude": 4.35, "start_date": start_date, "end_date": end_date, "hourly": "temperature_2m,shortwave_radiation,windspeed_10m"}
    response = requests.get("https://archive-api.open-meteo.com/v1/archive", params=params)
    if response.status_code == 200:
        data = response.json()['hourly']
        df_weather = pd.DataFrame(data)
        df_weather['time'] = pd.to_datetime(df_weather['time']).dt.tz_localize('UTC')
        df_weather.set_index('time', inplace=True)
        df_weather = df_weather.resample('15min').ffill()
    else:
        print("  - WARNING: Failed to fetch weather data. Proceeding without it.")
        df_weather = None

    # Step 3: Merge API data into the master DataFrame
    print("Step 3: Merging all data sources...")
    if df_dam is not None:
        master_df = master_df.join(df_dam, how='left')
    if df_weather is not None:
        master_df = master_df.join(df_weather, how='left')
        
    master_df.interpolate(method='time', inplace=True) # Good for filling gaps in time series
    master_df.fillna(method='ffill', inplace=True)

    # Step 4: Feature Engineering
    print("Step 4: Engineering features...")
    master_df['hour'] = master_df.index.hour
    master_df['day_of_week'] = master_df.index.dayofweek

    # Add month feature (1..12)
    master_df['month'] = master_df.index.month

    # Add is_weekend flag and one-hot encode it
    master_df['is_weekend'] = (master_df.index.dayofweek >= 5).astype(int)
    is_weekend_dummies = pd.get_dummies(master_df['is_weekend'], prefix='is_weekend', dtype=int)

    for lag in [1, 2, 4, 96]:
        master_df[f'actual_price_lag_{lag}'] = master_df['actual_price'].shift(lag)
    for window in [4, 96]:
        master_df[f'rolling_mean_{window}'] = master_df['actual_price'].shift(1).rolling(window=window).mean()
        master_df[f'rolling_std_{window}'] = master_df['actual_price'].shift(1).rolling(window=window).std()
    
    master_df.dropna(inplace=True)
    print("--- Data Engineering Pipeline Complete ---\n")
    return master_df

# --- Execute the Data Pipeline ---
if ENTSOE_API_KEY == "YOUR_API_KEY_HERE":
    print("--- WARNING: ENTSO-E API key is missing. ---")
    master_df = None
else:
    master_df = create_modeling_dataframe()











# --- MODEL TRAINING AND PERFORMANCE ANALYSIS ---
if master_df is not None and not master_df.empty:
    
    # Define Target and Features
    y = master_df['actual_price']
    X = master_df.drop(columns=['actual_price'])

    # Create Chronological Train-Test Split
    test_size = 672  # Last 7 days
    y_train, y_test = y.iloc[:-test_size], y.iloc[-test_size:]
    X_train, X_test = X.iloc[:-test_size], X.iloc[-test_size:]
    print(f"--- Data Split Complete: Training on {len(y_train)} records, Testing on {len(y_test)} records ---\n")

    # Train the SARIMAX Model
    print("--- Training SARIMAX Model ---")
    model = SARIMAX(endog=y_train, exog=X_train, order=(2, 1, 1), seasonal_order=(0, 0, 0, 0))
    model_fit = model.fit(disp=False)
    print("Model training complete.")
    print(model_fit.summary())

    # Make Predictions
    print("\n--- Making Predictions on Test Set ---")
    predictions = model_fit.forecast(steps=len(y_test), exog=X_test)

    # Performance Analysis
    mae = mean_absolute_error(y_test, predictions)
    rmse = np.sqrt(mean_squared_error(y_test, predictions))
    
    print("\n--- Model Performance Metrics ---")
    print(f"Mean Absolute Error (MAE):       {mae:.2f} EUR/MWh")
    print(f"Root Mean Squared Error (RMSE):  {rmse:.2f} EUR/MWh")
    print("---------------------------------")

    # Visualization
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(15, 7))
    plt.plot(y_test.index, y_test, label='Actual Prices', color='blue')
    plt.plot(predictions.index, predictions, label='SARIMAX Predictions', color='red', linestyle='--')
    plt.title('Forecast vs. Actual Prices on Test Set', fontsize=16)
    plt.xlabel('Time (UTC)'); plt.ylabel('Price (â‚¬/MWh)'); plt.legend()
    plt.show()
